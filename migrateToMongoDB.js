const { MongoClient } = require('mongodb');
const fs = require('fs');
const path = require('path');
require('dotenv').config({ path: './config.env' });

async function migrateToMongoDB() {
    const client = new MongoClient(process.env.MONGODB_URI);
    
    try {
        console.log('ğŸ”Œ Connecting to MongoDB Atlas...');
        await client.connect();
        console.log('âœ… Connected to MongoDB Atlas');
        
        const db = client.db(process.env.DATABASE_NAME);
        
        // Load and migrate positions data
        console.log('ğŸ“Š Loading positions data...');
        const positionsData = JSON.parse(fs.readFileSync(path.join(__dirname, 'data', 'positions.json'), 'utf-8'));
        console.log(`ğŸ“Š Found ${positionsData.length} positions to migrate`);
        
        const positionsCollection = db.collection(process.env.POSITIONS_COLLECTION);
        
        // Clear existing data if any
        await positionsCollection.deleteMany({});
        console.log('ğŸ—‘ï¸ Cleared existing positions data');
        
        // Insert in batches to handle large datasets
        const batchSize = 1000;
        for (let i = 0; i < positionsData.length; i += batchSize) {
            const batch = positionsData.slice(i, i + batchSize);
            await positionsCollection.insertMany(batch);
            console.log(`ğŸ“Š Inserted positions batch ${Math.ceil((i + 1) / batchSize)} of ${Math.ceil(positionsData.length / batchSize)}`);
        }
        
        // Create indexes for better query performance
        await positionsCollection.createIndex({ positionId: 1 }, { unique: true });
        await positionsCollection.createIndex({ cusip: 1 });
        await positionsCollection.createIndex({ trader: 1 });
        await positionsCollection.createIndex({ desk: 1 });
        await positionsCollection.createIndex({ instrumentType: 1 });
        console.log('ğŸ” Created indexes for positions collection');
        
        // Load and migrate trades data
        console.log('ğŸ’¼ Loading trades data...');
        const tradesData = JSON.parse(fs.readFileSync(path.join(__dirname, 'data', 'trades.json'), 'utf-8'));
        console.log(`ğŸ’¼ Found ${tradesData.length} trades to migrate`);
        
        const tradesCollection = db.collection(process.env.TRADES_COLLECTION);
        
        // Clear existing data if any
        await tradesCollection.deleteMany({});
        console.log('ğŸ—‘ï¸ Cleared existing trades data');
        
        // Insert in batches
        for (let i = 0; i < tradesData.length; i += batchSize) {
            const batch = tradesData.slice(i, i + batchSize);
            await tradesCollection.insertMany(batch);
            console.log(`ğŸ’¼ Inserted trades batch ${Math.ceil((i + 1) / batchSize)} of ${Math.ceil(tradesData.length / batchSize)}`);
        }
        
        // Create indexes for trades
        await tradesCollection.createIndex({ tradeId: 1 }, { unique: true });
        await tradesCollection.createIndex({ cusip: 1 });
        await tradesCollection.createIndex({ trader: 1 });
        await tradesCollection.createIndex({ tradeDate: 1 });
        await tradesCollection.createIndex({ side: 1 });
        await tradesCollection.createIndex({ status: 1 });
        console.log('ğŸ” Created indexes for trades collection');
        
        console.log('âœ… Migration completed successfully!');
        console.log(`ğŸ“Š Total positions migrated: ${positionsData.length}`);
        console.log(`ğŸ’¼ Total trades migrated: ${tradesData.length}`);
        
    } catch (error) {
        console.error('âŒ Migration failed:', error);
        process.exit(1);
    } finally {
        await client.close();
        console.log('ğŸ”Œ MongoDB connection closed');
    }
}

// Run migration if this script is executed directly
if (require.main === module) {
    migrateToMongoDB().catch(console.error);
}

module.exports = { migrateToMongoDB }; 